{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zID: z5379852\n",
    "\n",
    "Name: Qiyao Zhou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to rotate an input image\n",
    "# parameters:\n",
    "            # image: image to rotate\n",
    "            # x: x-coordinate of point we wish to rotate around\n",
    "            # y: y-coordinate of point we wish to rotate around\n",
    "            # angle: degrees to rotate image by\n",
    "# returns: rotated copy of the original image\n",
    "\n",
    "def rotate(image, x, y, angle):\n",
    "    rot_matrix = cv2.getRotationMatrix2D((x, y), angle, 1.0)\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    return cv2.warpAffine(image, rot_matrix, (w, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get coordinates of center point in an image\n",
    "# parameter:\n",
    "            # image: image that will be rotated\n",
    "# returns: (x,y) coordinates of point at the centre of an image\n",
    "\n",
    "def get_img_center(image):\n",
    "    height, width = image.shape[:2]\n",
    "    center = height // 2, width // 2\n",
    "    return center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Read the given sample image \"Cathedral.png\" and compute the SIFT features of the given image.\n",
    "- Extract SIFT features with default parameters and show the keypoints on the image.\n",
    "- To achieve better visualization of the keypoints, reduce the number of keypoints. Hint: Vary the parameter contrastThreshold or nfeatures so that the number of keypoints becomes about 10% of all default keypoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8383\n"
     ]
    }
   ],
   "source": [
    "# 1(a)\n",
    "img = cv2.imread('Cathedral.png')\n",
    "sift = cv2.SIFT_create(\n",
    "                nfeatures = 0,\n",
    "                nOctaveLayers = 3,\n",
    "                contrastThreshold = 0.03,\n",
    "                edgeThreshold = 10,\n",
    "                sigma = 1.6)\n",
    "kp = sift.detect(img,None)\n",
    "output = cv2.drawKeypoints(img,kp,img)\n",
    "print(len(kp))\n",
    "cv2.imwrite('1a.png',output)\n",
    "cv2.imshow('a',output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1(b)\n",
    "img = cv2.imread('Cathedral.png')\n",
    "sift = cv2.SIFT_create(\n",
    "                nfeatures = 0,\n",
    "                nOctaveLayers = 3,\n",
    "                contrastThreshold = 0.16,\n",
    "                edgeThreshold = 10,\n",
    "                sigma = 1.6)\n",
    "kp = sift.detect(img,None)\n",
    "output = cv2.drawKeypoints(img,kp,img)\n",
    "print(len(kp))\n",
    "cv2.imwrite('1b.png',output)\n",
    "cv2.imshow('b',output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Change the scale of the image and recompute the SIFT features.\n",
    "- Enlarge the given image by a scale percentage of 115.\n",
    "- Extract the SIFT features and show the keypoints on the scaled image using the same parameter setting as for Task 1 (for the reduced number of keypoints).\n",
    "- Inspect the keypoints visually: Are the keypoints of the scaled image roughly the same as those of the original image? What does this observation imply?\n",
    "- Match the SIFT descriptors of the keypoints of the scaled image with those of the original image using the nearest-neighbour distance ratio method. Show the keypoints of the 5 best-matching descriptors on both the original and the scaled image. Hint: Brute-force matching is available in OpenCV for feature matching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2(b)\n",
    "img = cv2.imread('Cathedral.png')\n",
    "res_row = int(img.shape[0]*1.15)\n",
    "res_column = int(img.shape[1]*1.15)\n",
    "res = cv2.resize(img, (res_column,res_row))\n",
    "sift = cv2.SIFT_create(\n",
    "                nfeatures = 0,\n",
    "                nOctaveLayers = 3,\n",
    "                contrastThreshold = 0.16,\n",
    "                edgeThreshold = 10,\n",
    "                sigma = 1.6)\n",
    "kp = sift.detect(res,None)\n",
    "output = cv2.drawKeypoints(res,kp,res)\n",
    "print(len(kp))\n",
    "cv2.imwrite('2b.png',output)\n",
    "cv2.imshow('b',output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2(c)The keypoints of the scaled image roughly the same as those of the original image though the number of the keypoints of the scaled image are much less than that of the original image.This means that the scale of the image does not affect the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2(d)\n",
    "img = cv2.imread('Cathedral.png')\n",
    "res_row = int(img.shape[0]*1.15)\n",
    "res_column = int(img.shape[1]*1.15)\n",
    "res = cv2.resize(img, (res_column,res_row))\n",
    "sift = cv2.SIFT_create(\n",
    "                nfeatures = 0,\n",
    "                nOctaveLayers = 3,\n",
    "                contrastThreshold = 0.16,\n",
    "                edgeThreshold = 10,\n",
    "                sigma = 1.6)\n",
    "kp1, des1 = sift.detectAndCompute(img, None)\n",
    "kp2, des2 = sift.detectAndCompute(res, None)\n",
    "bf = cv2.BFMatcher(cv2.NORM_L2)\n",
    "matches = bf.match(des1, des2)\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "m_img = cv2.drawMatches(img,kp1,res,kp2,matches[:5],None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "cv2.imwrite('2d.png',m_img)\n",
    "cv2.imshow('d',m_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Rotate the image and recompute the SIFT features.\n",
    "- Rotate the given image clockwise by 60 degrees and by 120 degrees. \n",
    "- Extract the SIFT features and show the keypoints on the rotated image using the same parameter setting as for Task 1 (for the reduced number of keypoints).\n",
    "- Inspect the keypoints visually: Are the keypoints of the rotated image roughly the same as those of the original image? What does this observation imply?\n",
    "- Match the SIFT descriptors of the keypoints of the rotated image with those of the original image using the nearest-neighbour distance ratio method. Show the keypoints of the 5 best-matching descriptors on both the original and the rotated image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n",
      "192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3(b)\n",
    "img = cv2.imread('Cathedral.png')\n",
    "x,y = get_img_center(img)\n",
    "img1 = rotate(img, x, y, -60)\n",
    "img2 = rotate(img, x, y, -120)\n",
    "sift = cv2.SIFT_create(\n",
    "                nfeatures = 0,\n",
    "                nOctaveLayers = 3,\n",
    "                contrastThreshold = 0.16,\n",
    "                edgeThreshold = 10,\n",
    "                sigma = 1.6)\n",
    "kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "output1 = cv2.drawKeypoints(img1,kp1,img1)\n",
    "output2 = cv2.drawKeypoints(img2,kp2,img2)\n",
    "cv2.imshow('3b1',img1)\n",
    "cv2.imshow('3b2',img2)\n",
    "cv2.imwrite('3b1.png',output1)\n",
    "cv2.imwrite('3b2.png',output2)\n",
    "print(len(kp1))\n",
    "print(len(kp2))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3(c)The keypoints of the rotated image roughly the same as those of the original image though the number of the keypoints of the rotated image are much less than that of the original image.This means that the rotate of the image does not affect the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3(d)\n",
    "kp, des = sift.detectAndCompute(img, None)\n",
    "bf = cv2.BFMatcher(cv2.NORM_L2)\n",
    "matches = bf.match(des, des1)\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "m_img1 = cv2.drawMatches(img,kp,img1,kp1,matches[:5],None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "m_img2 = cv2.drawMatches(img,kp,img2,kp2,matches[:5],None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "cv2.imshow('3d1',img1)\n",
    "cv2.imshow('3d2',img2)\n",
    "cv2.imwrite('3d1.png',m_img1)\n",
    "cv2.imwrite('3d2.png',m_img2)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
